{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import fsspec\n",
    "\n",
    "nwb_object_id = 'c86cdfba-e1af-45a7-8dfd-d243adc20ced'\n",
    "s3_url = f'https://dandiarchive.s3.amazonaws.com/blobs/{nwb_object_id[:3]}/{nwb_object_id[3:6]}/{nwb_object_id}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is way slow!\n",
    "fs = fsspec.filesystem('http')\n",
    "f = fs.open(s3_url)\n",
    "file = h5py.File(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's the much faster alternative\n",
    "\n",
    "import requests\n",
    "\n",
    "class HTTPRangeFile:\n",
    "    def __init__(self, url):\n",
    "        self._chunk_size = 100 * 1024\n",
    "        self._chunks = {}\n",
    "        self.url = url\n",
    "        self.position = 0\n",
    "        self._smart_loader_last_chunk_index_read = -99\n",
    "        self._smart_loader_string_length = 1\n",
    "        self._get_file_length()\n",
    "\n",
    "    def _get_file_length(self):\n",
    "        response = requests.head(self.url)\n",
    "        self.length = int(response.headers['Content-Length'])\n",
    "\n",
    "    def read(self, size=None):\n",
    "        chunk_start_index = self.position // self._chunk_size\n",
    "        chunk_end_index = (self.position + size - 1) // self._chunk_size\n",
    "        for chunk_index in range(chunk_start_index, chunk_end_index + 1):\n",
    "            self._load_chunk(chunk_index)\n",
    "        if chunk_end_index == chunk_start_index:\n",
    "            chunk = self._chunks[chunk_start_index]\n",
    "            chunk_offset = self.position % self._chunk_size\n",
    "            chunk_length = size\n",
    "            self.position += size\n",
    "            return chunk[chunk_offset:chunk_offset + chunk_length]\n",
    "        else:\n",
    "            pieces_to_concat = []\n",
    "            for chunk_index in range(chunk_start_index, chunk_end_index + 1):\n",
    "                chunk = self._chunks[chunk_index]\n",
    "                if chunk_index == chunk_start_index:\n",
    "                    chunk_offset = self.position % self._chunk_size\n",
    "                    chunk_length = self._chunk_size - chunk_offset\n",
    "                elif chunk_index == chunk_end_index:\n",
    "                    chunk_offset = 0\n",
    "                    chunk_length = size - sum([len(p) for p in pieces_to_concat])\n",
    "                else:\n",
    "                    chunk_offset = 0\n",
    "                    chunk_length = self._chunk_size\n",
    "                pieces_to_concat.append(chunk[chunk_offset:chunk_offset + chunk_length])\n",
    "        ret = b''.join(pieces_to_concat)\n",
    "        self.position += size\n",
    "        return ret\n",
    "    \n",
    "    def _load_chunk(self, chunk_index):\n",
    "        if chunk_index in self._chunks:\n",
    "            return\n",
    "        if chunk_index == self._smart_loader_last_chunk_index_read + 1:\n",
    "            # round up to the string length times 1.5\n",
    "            self._smart_loader_string_length = round(self._smart_loader_string_length * 1.5 + 0.5)\n",
    "            if self._smart_loader_string_length > 15 * 1024 * 1024 / self._chunk_size:\n",
    "                self._smart_loader_string_length = int(15 * 1024 * 1024 / self._chunk_size)\n",
    "        else:\n",
    "            self._smart_loader_string_length = 1\n",
    "        print(f\"Loading chunks {chunk_index} ({self._smart_loader_string_length})\")\n",
    "        data_start = chunk_index * self._chunk_size\n",
    "        data_end = data_start + self._chunk_size * self._smart_loader_string_length - 1\n",
    "        if data_end >= self.length:\n",
    "            data_end = self.length - 1\n",
    "        range_header = f\"bytes={data_start}-{data_end}\"\n",
    "        response = requests.get(self.url, headers={'Range': range_header})\n",
    "        x = response.content\n",
    "        if self._smart_loader_string_length == 1:\n",
    "            self._chunks[chunk_index] = x\n",
    "        else:\n",
    "            for i in range(self._smart_loader_string_length):\n",
    "                self._chunks[chunk_index + i] = x[i * self._chunk_size:(i + 1) * self._chunk_size]\n",
    "        self._smart_loader_last_chunk_index_read = chunk_index + self._smart_loader_string_length - 1\n",
    "\n",
    "    def seek(self, offset, whence=0):\n",
    "        if whence == 0:\n",
    "            self.position = offset\n",
    "        elif whence == 1:\n",
    "            self.position += offset\n",
    "        elif whence == 2:\n",
    "            self.position = self.length + offset\n",
    "        else:\n",
    "            raise ValueError(\"Invalid argument: 'whence' must be 0, 1, or 2.\")\n",
    "\n",
    "    def tell(self):\n",
    "        return self.position\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "f = HTTPRangeFile(s3_url)\n",
    "file = h5py.File(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is way slow as well\n",
    "\n",
    "import pynwb\n",
    "\n",
    "io = pynwb.NWBHDF5IO(file=file, load_namespaces=True)\n",
    "nwbfile = io.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file['acquisition'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = file['acquisition']['ElectricalSeries']['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[:800000, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
